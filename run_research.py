#!/usr/bin/env python3
"""
ç°¡åŒ–çš„ Open Deep Research æ¸¬è©¦è…³æœ¬
ä½¿ç”¨ Gemini 2.5 Pro æ¨¡å‹
"""

import asyncio
import time
from datetime import datetime
from dotenv import load_dotenv
from pprint import pprint, pformat
from src.app.config import Configuration, SearchAPI
from src.app.agents.research_agent import deep_researcher
import uuid

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


async def test_research():
    """æ¸¬è©¦ç ”ç©¶æµç¨‹"""

    print("ğŸš€ é–‹å§‹æ¸¬è©¦ Open Deep Research å®Œæ•´æµç¨‹")
    print("ä½¿ç”¨æ¨¡å‹: Gemini 2.5 Pro")
    print("=" * 50)

    # å‰µå»ºé…ç½®
    config = Configuration(
        research_model="gemini-2.5-pro",
        summarization_model="gemini-2.5-pro",
        compression_model="gemini-2.5-pro",
        final_report_model="gemini-2.5-pro",
        search_api=SearchAPI.TAVILY,
        max_concurrent_research_units=2,  # æ¸›å°‘ä¸¦ç™¼æ•¸ä»¥åŠ å¿«æ¸¬è©¦
        allow_clarification=False,  # è·³éæ¾„æ¸…æ­¥é©Ÿä»¥åŠ å¿«æ¸¬è©¦
        max_researcher_iterations=3,  # æ¸›å°‘è¿­ä»£æ¬¡æ•¸
        max_react_tool_calls=5  # æ¸›å°‘å·¥å…·èª¿ç”¨æ¬¡æ•¸
    )

    # è¨­ç½®é…ç½®
    run_config = {
        "configurable": {
            "thread_id": str(uuid.uuid4()),
            **config.model_dump(mode='json')
        }
    }

    # ç°¡å–®çš„ç ”ç©¶å•é¡Œ
    question = "è«‹ç°¡è¦ç ”ç©¶äººå·¥æ™ºæ…§åœ¨é†«ç™‚è¨ºæ–·æ–¹é¢çš„æœ€æ–°æ‡‰ç”¨"

    print(f"ğŸ“‹ ç ”ç©¶å•é¡Œ: {question}")
    print("â³ é–‹å§‹ç ”ç©¶...")

    try:
        start_dt = datetime.now().isoformat(timespec="seconds")
        start_time = time.perf_counter()
        # åŸ·è¡Œç ”ç©¶
        result = await deep_researcher.ainvoke(
            {"messages": [{"role": "user", "content": question}]},
            run_config
        )

        print("âœ… ç ”ç©¶å®Œæˆï¼")

        print(f"çµæœåŒ…å«: {list(result.keys())}")

        # é¡¯ç¤ºçµæœæ‘˜è¦
        if "messages" in result:
            print("\nğŸ“ ç ”ç©¶éç¨‹æ‘˜è¦:")
            print("-" * 30)
            for i, msg in enumerate(result["messages"]):
                if hasattr(msg, 'content'):
                    content = msg.content[:100] + \
                        "..." if len(msg.content) > 100 else msg.content
                    print(f"{i+1}. [{type(msg).__name__}]: {content}")
                    print()

        # é¡¯ç¤ºç ”ç©¶ç­†è¨˜
        if "notes" in result and result["notes"]:
            print("ğŸ“š ç ”ç©¶ç­†è¨˜:")
            print("-" * 30)
            for note in result["notes"]:
                print(f"- {note[:150]}...")
                print()

        end_time = time.perf_counter()
        end_dt = datetime.now().isoformat(timespec="seconds")
        elapsed = end_time - start_time
        print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")
        print(f"â±ï¸ åŸ·è¡Œæ™‚é–“: {elapsed:.2f} ç§’ (é–‹å§‹: {start_dt}, çµæŸ: {end_dt})")
        print("\nğŸ” å®Œæ•´ result å…§å®¹ï¼ˆå¯èƒ½è¼ƒé•·ï¼‰:")
        try:
            pprint(result, depth=3, width=100)
        except Exception:
            print(result)
        # å°‡å®Œæ•´çµæœå¯«å…¥æª”æ¡ˆ
        try:
            with open("output.txt", "w", encoding="utf-8") as f:
                f.write(
                    f"started_at: {start_dt}\nended_at: {end_dt}\nelapsed_seconds: {elapsed:.2f}\n")
                f.write("\n===== result (pretty) =====\n")
                f.write(pformat(result, depth=5, width=120))
                if isinstance(result, dict) and "final_report" in result:
                    f.write("\n\n===== final_report =====\n")
                    f.write(str(result["final_report"]))
            print("\nğŸ’¾ å·²å°‡å®Œæ•´çµæœå¯«å…¥ output.txt")
        except Exception as write_err:
            print(f"\nâš ï¸ å¯«å…¥ output.txt å¤±æ•—: {write_err}")
        return result
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    asyncio.run(test_research())
