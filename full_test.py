#!/usr/bin/env python3
"""
è©³ç´°çš„ç’°å¢ƒå’Œæ¨¡å‹æ¸¬è©¦
"""

import asyncio
import sys
import os
from pathlib import Path

# è¼‰å…¥ .env æª”æ¡ˆ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸  python-dotenv æœªå®‰è£ï¼Œè«‹é‹è¡Œ: pip install python-dotenv")

# æ·»åŠ srcç›®éŒ„åˆ°Pythonè·¯å¾‘
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))


def check_environment():
    """æª¢æŸ¥ç’°å¢ƒè¨­ç½®"""
    print("ğŸ”§ æª¢æŸ¥ç’°å¢ƒè¨­ç½®")
    print("=" * 50)

    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    gemini_key = os.getenv("GEMINI_API_KEY")
    tavily_key = os.getenv("TAVILY_API_KEY")

    print(f"GEMINI_API_KEY: {'âœ… å·²è¨­ç½®' if gemini_key else 'âŒ æœªè¨­ç½®'}")
    print(f"TAVILY_API_KEY: {'âœ… å·²è¨­ç½®' if tavily_key else 'âš ï¸  æœªè¨­ç½® (å¯é¸)'}")

    if gemini_key:
        print(f"   é‡‘é‘°é•·åº¦: {len(gemini_key)} å­—ç¬¦")
        print(f"   é‡‘é‘°å‰ç¶´: {gemini_key[:10]}...")

    return bool(gemini_key)


async def test_gemini_model():
    """æ¸¬è©¦ Gemini æ¨¡å‹"""
    print("\nğŸ§ª æ¸¬è©¦ Gemini æ¨¡å‹")
    print("=" * 50)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.messages import HumanMessage

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("âŒ GEMINI_API_KEY æœªè¨­ç½®")
            return False

        # å‰µå»ºæ¨¡å‹
        model = ChatGoogleGenerativeAI(
            model="gemini-2.5-pro",
            temperature=0.2,
            max_output_tokens=1000,
            google_api_key=api_key
        )
        print("âœ… Gemini æ¨¡å‹å‰µå»ºæˆåŠŸ")

        # æ¸¬è©¦ç°¡å–®å°è©±
        print("ğŸ“ ç™¼é€æ¸¬è©¦è¨Šæ¯...")
        response = await model.ainvoke([
            HumanMessage(content="è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹äººå·¥æ™ºæ…§")
        ])

        print("âœ… æ¨¡å‹å›æ‡‰æˆåŠŸ:")
        print(f"   {response.content}")

        return True

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_research_agent():
    """æ¸¬è©¦ç ”ç©¶ä»£ç†"""
    print("\nğŸ” æ¸¬è©¦ç ”ç©¶ä»£ç†")
    print("=" * 50)

    try:
        from app.agents.research_agent import deep_researcher
        from app.config import Configuration
        from langchain_core.messages import HumanMessage

        # å‰µå»ºé…ç½®
        config = Configuration()
        print(f"âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
        print(f"   ç ”ç©¶æ¨¡å‹: {config.research_model}")

        # å‰µå»ºé‹è¡Œé…ç½®
        runnable_config = {
            "configurable": {
                "search_api": config.search_api.value,
                "max_researcher_iterations": 1,  # é™åˆ¶è¿­ä»£æ¬¡æ•¸
                "max_concurrent_research_units": 1,
                "research_model": config.research_model,
                "compression_model": config.compression_model,
                "final_report_model": config.final_report_model,
                "summarization_model": config.summarization_model,
                "plan_model": config.plan_model,
                "api_key": os.getenv("GEMINI_API_KEY")
            }
        }

        # æ¸¬è©¦ç°¡å–®çš„ç ”ç©¶ä¸»é¡Œ
        test_topic = "ä»€éº¼æ˜¯äººå·¥æ™ºæ…§ï¼Ÿ"
        print(f"ğŸ” æ¸¬è©¦ä¸»é¡Œ: {test_topic}")

        # é‹è¡Œç ”ç©¶ä»£ç†
        result = await deep_researcher.ainvoke(
            {"messages": [HumanMessage(content=test_topic)]},
            config=runnable_config
        )

        print("âœ… ç ”ç©¶ä»£ç†æ¸¬è©¦æˆåŠŸ!")
        if "final_report" in result:
            print("ğŸ“„ ç ”ç©¶å ±å‘Š:")
            print(result["final_report"])

        return True

    except Exception as e:
        print(f"âŒ ç ”ç©¶ä»£ç†æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ æ·±åº¦ç ”ç©¶ä»£ç†å®Œæ•´æ¸¬è©¦")
    print("=" * 60)

    # æª¢æŸ¥ç’°å¢ƒ
    env_ok = check_environment()
    if not env_ok:
        print("\nâŒ ç’°å¢ƒè¨­ç½®ä¸å®Œæ•´ï¼Œè«‹å…ˆè¨­ç½® GEMINI_API_KEY")
        print("   ä¾‹å¦‚: set GEMINI_API_KEY=your_api_key_here")
        return

    # æ¸¬è©¦ Gemini æ¨¡å‹
    model_ok = await test_gemini_model()
    if not model_ok:
        print("\nâŒ Gemini æ¨¡å‹æ¸¬è©¦å¤±æ•—")
        return

    # æ¸¬è©¦ç ”ç©¶ä»£ç†
    agent_ok = await test_research_agent()
    if not agent_ok:
        print("\nâŒ ç ”ç©¶ä»£ç†æ¸¬è©¦å¤±æ•—")
        return

    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦éƒ½é€šéäº†ï¼ç³»çµ±æº–å‚™å°±ç·’ï¼")

if __name__ == "__main__":
    asyncio.run(main())
